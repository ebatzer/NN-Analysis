---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

# Preparing datasets for analysis

Compiled on `r date()`

```{r, message = FALSE, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE,fig.width = 5, fig.height = 3.5)

# Loading necessary packages
library(tidyverse) # Data manipulation
library(vegan) # General ecology functions
library(data.table) # Fast reading of data tables
library(testthat) # Unit testing
library(dtplyr) #Dplyr for data.table

# Write new datasets?
write_datasets = TRUE
```

### Reading in datasets

```{r}
# Biomass data
biomass_data <- fread("../../Data/comb-by-plot-23-april-2020.csv",
                      stringsAsFactors = FALSE,
                      na.strings = c('NA','NULL'))

biomass_data %>% filter(site_code == "sevi.us" & trt == "P")

# Cover
cover <- fread('../../Data/full-cover-23-april-2020.csv',
               stringsAsFactors = FALSE,
               na.strings = c('NA','NULL'))

# Analysis parameters
min_yr_trt <- 5 # Number of years minimum to be included in analysis
```

#### Cleaning datasets

```{r}
# Converting some columns to factor prior to joining
biomass_data$site_code <- factor(biomass_data$site_code)
biomass_data$trt <- factor(biomass_data$trt)

# Generate table of sites by years of treatment
sites_table <- biomass_data %>% 
  group_by(site_code,region,first_nutrient_year) %>% 
  summarise(yrs.data = length(unique(year)),
            fyear = min(year), 
            lyear = max(year)) %>% 
  arrange(yrs.data)

# Create site vector sites with at least X years of data
sites_table.long <- sites_table['yrs.data' >= min_yr_trt, 'site_code']
sites_table.long$site_code <- as.character(sites_table.long$site_code)

# Filtering cover data to just live plants
cover.long <- cover[site_code %in% c(sites_table.long$site_code) & live==1,]
cover.long$max_cover = as.numeric(cover.long$max_cover)

# Cleaning workspace
rm(sites_table, cover)
```

### Taxonomic Adjustments from Bakker

```{r}
source("../Taxonomic.Adjustments.function.200521.R")


```




### Editing datasets, converting to wide format

```{r}
# Choosing only our treatments of interest
cover.long <- cover.long[trt %in% c('Control','N','P','K')]

# Clean out unknowns, non-vascular plants
sps <- unique(cover.long$Taxon)
unwanted.sps <- sps[c(grep('UNKNOWN',sps),grep('BRYOPHYTE',sps),grep('LICHEN',sps))]

cover.long <- cover.long[!(Taxon %in% unwanted.sps | local_lifeform == 'MOSS' | functional_group == 'BRYOPHYTE')]

# Removing the "GRAMINOID" functional group label, converting to just "GRASS"
cover.long[functional_group =='GRAMINOID', functional_group := 'GRASS']

# Filtering odd plot layouts
## Some sites have multiple control plots in a block.
## Choosing only the lowest numbered plot belong to a treatment in each block.
## This takes care of a few sites that have strange plot configurations,
## like sgs.us

site.plots.keep <- cover.long %>% 
  group_by(site_code,block,plot,trt) %>% 
  summarise(yrs.data = max(year_trt)) %>% 
  filter(yrs.data >= min_yr_trt)

filtering_min_plot <- site.plots.keep %>% 
  group_by(site_code,block,trt) %>% 
  summarize(min.plot = min(plot)) %>%
  
  # Making species allowance for Sevilleta
  filter(site_code != "sevi.us") %>%
  bind_rows(site.plots.keep %>% 
              filter(site_code == "sevi.us") %>%
              mutate(min.plot = plot)) %>%
  select(-plot, -yrs.data)

site.plots.keep <- left_join(site.plots.keep, filtering_min_plot) %>% 
  filter(plot == min.plot)

# Joining into master long-format cover dataframe
cover.long <- left_join(site.plots.keep, cover.long)

# Remove unused factor levels
cover.long <- droplevels(cover.long) 

# cast long into wide
cover.wide <- reshape2::dcast(cover.long,site_code+year+block+plot+trt+year_trt ~ Taxon,
                              value.var='max_cover', 
                              fun.aggregate = sum,drop=T,fill=0)

# Cleaning workspace
rm(sps, unwanted.sps, site.plots.keep)

if(write_datasets){
  write.csv(x = cover.wide, "../../Data/cover_wide_tradeoffs.csv")
  write.csv(x = cover.long, "../../Data/cover_long_tradeoffs.csv")
}
```

### Summarizing available datasets

```{r}
# Histogram of number of observations
## Some sites seem to have uneven number of observations within each treatment
cover.wide %>% 
  group_by(site_code, trt) %>%
  summarise(obs = n(),
            yrtrt = max(year_trt)) %>%
  ggplot(aes(x = obs,
             fill = trt)) +
  geom_histogram(alpha = .5, position = position_dodge()) +
  ggtitle("Distribution of Observations")
```

#### Summarising species attributes at each site

Potential filtering categories:

* Mean overall cover
* Mean cover in control
* Max overall cover
* Total occupancy
* Occupancy in control

Note: Must correct for zero observations when calculating mean and max values, so multiplying mean cover by occupancy (operation is linear, so order shouldn't matter)

```{r}
# Tabulating statistics by species
spec_stats <- cover.long %>%
  group_by(site_code, trt, Taxon) %>%
  
  # Total number of observations by treatment and site, and mean cover
  summarise(n_obs = n(),
            mean_cover = mean(max_cover)) %>%
  
  # Pivot the above variablesto wide format (makes other manipulations easier)
  pivot_wider(names_from = trt,
              values_from = c(mean_cover, n_obs)) %>%
  
  # Replace NA's with 0
  replace(., is.na(.), 0)

# Tabulate number of observations in each site -- by block, so comparable with above. Defines maximum number of possible observations
site_obs <- cover.long %>%
  ungroup() %>%
  select(site_code, year, block) %>%
  distinct() %>%
  group_by(site_code) %>%
  summarise(total_obs = n())

# Finalize calculations
specfilters <- full_join(site_obs, spec_stats) %>%
  
  # Define the number of observation variables as fractions of total potential observations
  mutate_at(vars(contains("n_obs")), funs(. / total_obs)) %>%
  
  # Correct mean cover by multiplying by this fraction of potential observation
  mutate(mean_cover_Control = mean_cover_Control * n_obs_Control,
         mean_cover_P = mean_cover_P * n_obs_P,
         mean_cover_K = mean_cover_K * n_obs_K,
         mean_cover_N = mean_cover_N * n_obs_N) %>%
  
  # Species found in all plots at least once
  mutate(alltrts = (rowSums(select(., contains("n_obs")) > 0)) == 4) %>%
  
  # Finalize the dataset by selecting desired variables
  transmute(site_code = site_code,
            Taxon = Taxon,
            Total_Obs = total_obs,
            Occ_Control = n_obs_Control,
            Occ_Total = rowMeans(select(., contains("n_obs"))),
            Cov_Control = mean_cover_Control,
            Cov_Total = rowMeans(select(., contains("mean_cover"))),
            All_Trts = alltrts)

if(write_datasets){
  write.csv(x = specfilters,
            "../../Data/tradeoffs_species_filtering.csv")
}
```

```{r}
# Cover
cover <- fread('../../Data/full-cover-23-april-2020.csv',
               stringsAsFactors = FALSE,
               na.strings = c('NA','NULL'))

taxonomy <- cover %>% 
  # filter(Family != "NULL" & N_fixer != "NULL") %>%
  group_by(site_code, Taxon) %>%
  summarise(ps_path = unique(ps_path),
            functional_group = unique(functional_group)[1],
            N_fixer = unique(N_fixer)[1]) %>%
  mutate(functional_group = case_when(functional_group == "GRAMINOID" ~ "Graminoid",
                                      functional_group == "GRASS" ~ "Graminoid",
                                      functional_group == "LEGUME" ~ "Legume",
                                      functional_group == "WOODY" ~ "Woody",
                                      functional_group == "FORB" ~ "Forb")) %>%
  mutate(Taxon = gsub("\\.", " ", Taxon)) %>%
  mutate(Taxon = tolower(str_trim(Taxon)))

write.csv(taxonomy,
          "../../Data/tradeoffs_taxonomy.csv")
```

