---
title: "R Notebook"
output: html_notebook
---

### Loading Necessary Packages

```{r, message = FALSE, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE,fig.width = 5, fig.height = 3.5)

# Loading necessary packages
library(tidyverse) # Data manipulation
library(vegan) # General ecology functions
library(data.table) # Fast reading of data tables
library(testthat) # Unit testing
library(fastDummies) # Fast generation of dummy variables
# library(dtplyr) #Dplyr for data.table
library(RRPP) # RRPP for multivariate model fittinginsta
library(gridExtra)
library(grid)
library(wesanderson)
library(VennDiagram)

# Should I re-write old datasets?
write_datasets = TRUE
```

### Reading in Dataframes

```{r}
# Community data wide format
cover.wide <- read.csv("../../Data/cover_wide_tradeoffs.csv")

# Site attributes
site.attr <- read.csv("../../Data/comb-by-plot-23-april-2020.csv")

# Analysis parameters
min_yr_trt <- 5 # Number of years minimum to be included in analysis

# Number of iterations in RRPP
num_iter <- 9999

```

### Subsetting datasets to attribute and community matrices

```{r}
# Checking that all cover values are numeric
cols <- c(colnames(cover.wide)[-c(1:6)])
cover.wide[-c(1:6)] <- apply(cover.wide[-c(1:6)], MARGIN = 2, FUN = as.numeric)

# Separating dataframe into cover and attribute
attr.mat = cover.wide[,1:7] %>% column_to_rownames(var="X")
cover.vals = data.frame(cover.wide[,-c(2:7)]) %>% column_to_rownames(var="X")

# Should we normalize?
## Normalizing might be standard if we're dealing in proportions
## However, we have a minimum cover threshold, usually about .5
## normalizing in this case might cause problems if we have total cover increasing
## this can cause low-abundance species to become less abundant, even if they are
## the same absolute abundance in both cases

# cover.mat = round(vegan::decostand(cover.vals, method = "total"), 3)
cover.mat = cover.vals

# Creating new dummy variables that refer to numeric treatment effects
attr.mat = dummy_columns(attr.mat, 
                         select_columns = "trt",
                         remove_first_dummy = TRUE) %>%
  replace_na(list(trt_K = 0, trt_N = 0, trt_P = 0)) %>%
  mutate(trt_K_num =log(as.numeric(trt_K * year_trt) + 1),
         trt_P_num =log(as.numeric(trt_P * year_trt) + 1),
         trt_N_num =log(as.numeric(trt_N * year_trt) + 1))

# Setting treatment effects to zero for the first year of treatment
attr.mat$trt_K[attr.mat$year_trt == 0] = 0
attr.mat$trt_P[attr.mat$year_trt == 0] = 0
attr.mat$trt_N[attr.mat$year_trt == 0] = 0


# Creating dataset of sites used in the analysis
sites_df <- left_join(attr.mat %>% select(site_code, plot, year), site.attr, by = c("site_code", "plot", "year")) %>% 
  group_by(site_code) %>%
  summarise(site_name = unique(site_name),
            continent = unique(continent),
            country = unique(country),
            n_years = length(unique(year)),
            n_obs = n(),
            first_nutrient_year = unique(first_nutrient_year)) %>%
  filter(!(site_code%in% c("doane.us", "pape.de")))

if(write_datasets){
  
  write.csv("../../Data/tradeoffs_selectedsites.csv",
            x = sites_df)
  
  write.csv("../../Data/tradeoffs_comm.csv",
            x = cover.mat,
            row.names = FALSE)
  
  write.csv("../../Data/tradeoffs_attr.csv",
            x = attr.mat,
            row.names = FALSE)
}

# Cleaning workspace
rm(cover.wide, cover.vals)
```

### Fitting RRPP models to each site

```{r}
output_list <- list()
counter <- 1

sitenames = unique(attr.mat$site_code)
sitenames = sitenames[!(sitenames %in% c("doane.us", "pape.de"))]

# For all unique sites selected
for(sites in sitenames){

  print(paste(counter,":", sites))

  # Subset to a single site
  com.subset <- cover.mat[attr.mat$site_code == sites,]

  # Remove all zero columns
  com.subset <- com.subset[,colSums(com.subset) > 0]
  
  # Set lowest value equal to one
  com.subset[com.subset > 0 & com.subset < 1] = 1
  com.subset = round(com.subset)
  
  # Standardize to log scale
  com.subset <- decostand(com.subset, method = "log")

  # Pull out relevant plot attributes for each site
  attr.subset <- data.frame(attr.mat) %>%
    filter(site_code == sites) %>%
    mutate(year_trt = as.factor(year_trt),
           plot = as.factor(plot),
           block = as.factor(block))

  # Check that these two matrices are the same size
  expect_true(nrow(attr.subset) == nrow(com.subset))
  expect_true(nrow(attr.subset) > 0)
  
  if(length(unique(attr.subset$block)) > 1){
      mod_rrpp <- lm.rrpp(com.subset ~ year_trt + trt_K_num + trt_P_num + trt_N_num + block,
                      data = attr.subset,
                      SS.type = "III",
                      iter = num_iter,
                      print.progress = FALSE)
  }else{
      mod_rrpp <- lm.rrpp(com.subset ~ year_trt + trt_K_num + trt_P_num + trt_N_num,
                      data = attr.subset,
                      SS.type = "III",
                      iter = num_iter,
                      print.progress = FALSE)
  }


  # Saving ouput
  output = list(siteinfo = attr.subset,
                aovtable = anova(mod_rrpp, effect.type = "F"),
                specscores = coef(mod_rrpp))

  output_list[[counter]] = output
  counter = counter + 1
}
```

```{r}
storagelist <- list()

for(i in 1:length(output_list)){

  anovatab = bind_cols(site = as.character(unique(output_list[[i]]$siteinfo$site_code)),
            data.frame(matrix(output_list[[i]]$aovtable$table$`Pr(>F)`, nrow = 1)))

  colnames(anovatab)[2:ncol(anovatab)] = rownames(output_list[[i]]$aovtable$table)

  storagelist[[i]] = anovatab

}

if(write_datasets){
  write.csv(x = bind_rows(storagelist), "../../Data/tradeoffs_RRPP_Pvals.csv")
}

storagelist <- list()

for(i in 1:length(output_list)){

  anovatab = data.frame(site = as.character(unique(output_list[[i]]$siteinfo$site_code)),
                        var = rownames(output_list[[i]]$aovtable$table),
            data.frame(matrix(c(output_list[[i]]$aovtable$table$SS,
                                output_list[[i]]$aovtable$table$Df,
                                output_list[[i]]$aovtable$table$`Pr(>F)`), ncol= 3)))

  colnames(anovatab)[2:ncol(anovatab)] = c("Source", "SumofSquares", "DF", "P_Value")

  storagelist[[i]] = anovatab

}

if(write_datasets){
  write.csv(x = bind_rows(storagelist),"../../Data/tradeoffs_RRPP_Pvals_Summary.csv")
}

storagelist <- list()

for(i in 1:length(output_list)){
  sp_scores = data.frame(output_list[[i]]$specscores[grep("trt_", rownames(output_list[[i]]$specscores)),])

  tomatch = c(4:10)
  # sp_scores = sp_scores[grepl(paste(tomatch, collapse = "|"), rownames(sp_scores)),]

  spectab = bind_cols(site = rep(unique(output_list[[i]]$siteinfo$site_code), nrow(sp_scores)),
                    trt = rownames(sp_scores),
                    sp_scores)

  storagelist[[i]] = spectab %>% mutate(trt = gsub("_num", "", trt))
}

specscores_full = data.frame(bind_rows(storagelist))
specscores_full[is.na(specscores_full)] = 0

specscores_long <- specscores_full %>% 
  pivot_longer(cols = -c("site", "trt"), names_to = "Taxon") %>% 
  pivot_wider(names_from = "trt", values_from = "value") %>%
  filter(!(trt_K == 0 & trt_P == 0 & trt_N == 0))

if(write_datasets){
  write.csv(specscores_full, "../../Data/tradeoffs_specscores.csv")
  write.csv(specscores_long, "../../Data/tradeoffs_specscores_long.csv")
}
```

### Calculate dot-product of pairwise correlations

Given these estimated parameters, we can calculate the correlation between species responses
to different pairs of nutrient treatments through the dot-product of the fitted
vectors between treatments within a site.

After calculating this dot-product, the distributions of each set correlation scores can be seen in histograms below:

* Values close to zero indicate that species responses to two treatments within a site are not correlated with one another.

* Values close to one or negative one indicate that species responses to two treatments within a site are highly positively or negatively correlated.

```{r}
# Normalization function -- squared sums of vector = 1
scalar1 <- function(x) {x / sqrt(sum(x^2))}

# Defining dot-product function
dotprod <- function(x, normalize = TRUE){

  # First, select the appropriate treatment and remove columns that aren't plant response
  N_vec <- x %>% filter(trt == "trt_N") %>% select(-trt, -site)
  P_vec <- x %>% filter(trt == "trt_P") %>% select(-trt, -site)
  K_vec <- x %>% filter(trt == "trt_K") %>% select(-trt, -site)

  N_change <- sqrt(sum(N_vec^2))
  P_change <- sqrt(sum(P_vec^2))
  K_change <- sqrt(sum(K_vec^2))

  # If normalizing, run the normalize function on each vector
  if(normalize == TRUE){
    N_vec <- scalar1(N_vec)
    P_vec <- scalar1(P_vec)
    K_vec <- scalar1(K_vec)
  }

  # Generate output dataframe of dot products (pracma::dot function)
  output = data.frame(NP = pracma::dot(as.numeric(N_vec), as.numeric(P_vec)),
                      NK = pracma::dot(as.numeric(N_vec), as.numeric(K_vec)),
                      PK = pracma::dot(as.numeric(P_vec), as.numeric(K_vec)),
                      N_change = N_change,
                      P_change = P_change,
                      K_change = K_change)

  return(output)

}

# Run over our dataset
dotoutput = specscores_full %>% group_by(site) %>%
  do(dotprod(.))

# Load permANOVA p-value output
site_pvals = read.csv("../../Data/tradeoffs_RRPP_Pvals.csv", header = TRUE, stringsAsFactors = FALSE)

# Join all together (sites, treatments, dot-product pairs, perMANOVA p-values)
dot_full = left_join(site_pvals %>% select(-Total, -Residuals), dotoutput) %>%
  select(-X) %>%
  rename("trt_K" = "trt_K_num", "trt_P" =  "trt_P_num", "trt_N" = "trt_N_num")

# Write final data product
if(write_datasets){
  write.csv(x = dot_full, "../../Data/dot_full.csv")
}
```


```{r}
mag_summary <- dot_full %>% select(site, N_change, P_change, K_change) %>%
  pivot_longer(cols = -"site",
               names_to = "trt",
               values_to = "magnitude")

library(lme4); library(lmerTest)
summary(lmer(log(magnitude) ~ trt + (1|site), data = mag_summary))
plot(lmer(log(magnitude) ~ trt + (1|site), data = mag_summary))

```



```{r}
sigtally <- site_pvals %>% select(trt_N_num, trt_P_num, trt_K_num) %>%
  mutate_all(function(x) x < 0.05) %>%
  mutate(NP = trt_N_num == 1 & trt_P_num == 1,
         NK = trt_N_num == 1 & trt_K_num == 1,
         PK = trt_P_num == 1 & trt_K_num == 1,
         NPK = trt_N_num == 1 & trt_P_num == 1 & trt_K_num == 1)  %>%
  mutate_all(as.numeric) %>%
  rename("K" = "trt_K_num",
         "N" = "trt_N_num",
         "P" = "trt_P_num") %>%
  summarise_all(sum) %>%
  gather()

sigtally$key = factor(sigtally$key, levels = sigtally$key)

sigtally %>% ggplot(aes(x = key,
                        y = value / nrow(site_pvals),
                        fill = key)) +
  geom_bar(aes(y = 1), stat = "identity", fill = "white", color = "black") +
  geom_bar(stat = "identity", color = "black") +
  scale_fill_manual(values = c("cadetblue1", "cadetblue3", "cadetblue4", "gold", "gold3", "gold4", "brown3")) +
  ylim(0, 1) +
  ylab("Proportion of Sites where P < 0.05") +
  xlab("Coefficients")

list(venn_dat$trt_N_num[grep("TRUE", venn_dat$trt_N_num)], 
     venn_dat$trt_P_num[grep("TRUE", venn_dat$trt_P_num)], 
     venn_dat$trt_K_num[grep("TRUE", venn_dat$trt_K_num)])
```

### Plotting as a Venn Diagram

```{r}
venn_dat <- site_pvals %>% select(trt_N_num, trt_P_num, trt_K_num) %>%
  mutate_all(function(x) paste(1:length(x), x < 0.05)) 

sig_levels <- paste(rep(1:nrow(venn_dat), 2), sort(rep(c(TRUE, FALSE), nrow(venn_dat)), decreasing = TRUE))

venn_dat <- venn_dat %>%
  mutate_all(function(x) factor(x, levels = sig_levels)) %>%
  mutate_all(as.numeric)

venn_list <- list(N = venn_dat$trt_N_num[venn_dat$trt_N_num < 50], 
                 P = venn_dat$trt_P_num[venn_dat$trt_P_num < 50], 
                 K = venn_dat$trt_K_num[venn_dat$trt_K_num < 50])

myvenn <- venn.diagram(
        x = list(c(venn_dat$trt_N_num[venn_dat$trt_N_num < 50], 50), 
                 venn_dat$trt_P_num[venn_dat$trt_P_num < 50], 
                 venn_dat$trt_K_num[venn_dat$trt_K_num < 50]),
        category.names = c("+N" , "+P" , "+K"),
        filename = '../../Figures/tradeoffs_venn.tiff',
        output=TRUE,
        scaled = FALSE,
        
        # Output features
        imagetype="tiff" ,
        height = 480 , 
        width = 480 , 
        resolution = 300,
        compression = "lzw",
        
        # Circles
        lwd = .5,
        lty = 1,
        fill = wes_palette("Darjeeling1", 3),
        
        # Numbers
        cex = .6,
        fontface = "bold",
        fontfamily = "sans",
        
        # Set names
        cat.cex = 0.8,
        cat.fontface = "bold",
        cat.default.pos = "outer",
        cat.pos = c(-45, 45, 180),
        cat.dist = c(0.085, 0.085, 0.085),
        cat.fontfamily = "sans",
        rotation = 1
        
        
)
```
