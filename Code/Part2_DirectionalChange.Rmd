---
title: "R Notebook"
output:
  rmarkdown::html_document:
    theme: lumen
---

```{r, message = FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      fig.width = 5, fig.height = 3.5)

# Loading necessary packages
library(ggplot2) # Figure plotting
library(tidyverse) # Data manipulation
library(vegetarian) # Exponentiated diversity indices (Hill Numbers)
library(lme4) # Linear mixed effects models
library(vegan) # General ecology functions
library(data.table) # Fast reading of data tables
library(testthat) # Unit testing
library(plotly) # Interactive graphics
library(metafor) # Response ratios
library(testthat)
library(fastDummies)
library(grid)
library(dtplyr)
library(gridExtra)
```

Compiled on `r date()`

# Fertilization Vector Analysis

## Results of statistical consultation

Per discussions with Neil Willits (statistical consultant at UC Davis), the two different ways that I could try to 
analyze the nutrient enrichment tradeoff include:

* Conducting a PCA on each site and trying to evaluate nutrient enrichment
change as a linear model. In this case, we have Y = PC1 score (or some other
principal component axis), and $$Y = \mu + \beta_i t + f_i(t)$$, where $\beta_i$ 
is the effect of nutrient enrichment over time and $f_i$ is a nonlinear term that 
reflects the fact that the relationship between time and response isn't apt to be linear.

    * To evaluate the tradeoff between nutrient addition treatments (or if this surface
    exists at all!), we can compare the values of the beta coefficient. For example,
    $\beta_N$ - $\beta_P$ is equal to the tradeoff on this axis. The more negative
    value this is, the greater of a tradeoff we see.
    
    * However, I'm not crazy about this approach, in large part because of the
    difficulty in picking the appropriate principal components. How can we standardize
    this process over multiple sites? Without running the analysis over all of the
    total variation between sites, this is not clear to me.
    
* Another potential way to understand how communities differ in their response to nutrient enrichment is to compare observed vectors of change. But rather than actually calculating the multivariate angle by
the formula:
$$\cos (\theta) = \frac{(\vec{V_N} \cdot \vec{V_P})}{\left\lVert\vec{V_N}
\right\rVert \left\lVert\vec{V_P}\right\rVert}$$ we can instead just focus on the dot
product itself, or the ratio relative to the magnitude of each vector. 

    * Neil suggested that the computation that derives the angle $\theta$ can be
    a little unstable. Focusing on the dot product (if we divide by the magnitude
    or convert to unit length) can give us a value between -1 and 1, which indicates 
    travel in either the same or opposite directions.
    
    * I like this approach more, because it doesn't rely on a dimensionality reduction, or
    a summary statistic like grass/forb/legume cover. 

## PermANOVA analysis

__Steps:__

1. Run permANOVA for each site, specifying:

  * Permutations only within blocks
  * Model formula of Y ~ Yearly variation effect + linear treatment effect over time
      * Can also specify a log-transformed term of treatment, or some sort of factor-level treatment effect
        
2. Summarize this data by tabulating treatment effects and PerMANOVA output.

  * Which sites show community change by N, P, and K? 
  * Should we just subset to these sites with significant results?

3. Extract vectors of community change in response to N, P, and K.

4. Calculate the dot product for each pairwise set of vectors. Store this value (bounded between -1 and 1, equivalent to correlation coefficient)

5. To establish which sorts of sites seem to experience this tradeoff, we can perform
some sort of hierarchical clustering algorithm. Neil suggested using conditional 
inference trees with some sort of univariate control, as opposed to the standard 
Bonferroni method. However, initial attempts to make this run weren't successful 
-- relatively low number of sites relative to variance. Simpler univariate methods may be a good place to start.

## Fitting PerMANOVA to these sites

### Reading in Datasets

(Code omitted)

```{r}
# Biomass data
biomass_data <- fread("../Data/comb-by-plot-22-February-2019.csv",
                  stringsAsFactors = FALSE,
                  na.strings = c('NA','NULL'))

# Loading in dataset (Updated to Feb 22st 2019)
cover <- fread('../Data/full-cover-22-February-2019.csv',
                  stringsAsFactors = FALSE,
                  na.strings = c('NA','NULL'))

# Plot descriptions
plot.descriptions <-  read.csv("../Data/comb-by-plot-clim-soil-diversity-22-Feb-2019.csv",
                              stringsAsFactors = FALSE)

# Soil characteristics
soil.chars <- read.csv("../Data/soil-nutrients-21-February-2019.csv",
                              stringsAsFactors = FALSE)

# Site covariates
site.covars <- read.csv("../Data/site_covars.csv",
                        stringsAsFactors = FALSE)

```

#### Cleaning datasets

(Code omitted)

```{r}
# Converting some columns to factor prior to joining
biomass_data$site_code <- factor(biomass_data$site_code)
biomass_data$trt <- factor(biomass_data$trt)

#Choose sites with at least 3 years of data
sites <- biomass_data %>% 
  group_by(site_code,region,first_nutrient_year) %>% 
  summarise(yrs.data = length(unique(year)),fyear = min(year), lyear = max(year)) %>% 
  arrange(yrs.data)

sites.long <- as.character(sites[yrs.data >= 3,`site_code`])

bmass <- biomass_data[site_code %in% sites.long]

cover.long <- cover[site_code%in%c(sites.long) & live==1,]
cover.long <- left_join(cover.long,distinct(bmass[,.(`site_code`,`region`)]))
cover.long$max_cover = as.numeric(cover.long$max_cover)

rm(sites)

```

```{r}
#Choosing only our treatments of interest
cover.long <- cover.long[trt %in% c('Control','N','P','K')]

#Clean out unknowns, non-vascular plants
sps <- unique(cover.long$Taxon)
unwanted.sps <- sps[c(grep('UNKNOWN',sps),grep('BRYOPHYTE',sps),grep('LICHEN',sps))]
cover.long <- cover.long[!(Taxon %in% unwanted.sps | local_lifeform == 'MOSS' | functional_group == 'BRYOPHYTE')]
cover.long[functional_group=='GRAMINOID', functional_group := 'GRASS']
rm(sps,unwanted.sps)
rm(sps,unwanted.sps)

#Choose plots with at least 3 years of data
## This takes care of a few sites that have strange plot configurations,
## like sgs.us
site.plots.keep <- cover.long %>% 
  group_by(site_code,block,plot,trt) %>% 
  summarise(yrs.data = length(unique(year))) %>% 
  filter(yrs.data>= 5)

## Some sites have multiple control plots in a block.
## Choosing only the lowest numbered plot belong to a treatment in each block.
site.plots.keep <- left_join(site.plots.keep,
                             site.plots.keep %>% group_by(site_code,block,trt) %>% 
                               summarize(min.plot = min(plot))) %>% 
  filter(plot==min.plot) %>% 
  select(-min.plot,-yrs.data)

cover.long <- left_join(site.plots.keep,cover.long)

cover.long <- droplevels(cover.long) #cover.long$site_code <- factor(cover.long$site_code)
rm(site.plots.keep)

# cast long into wide
cover.wide <- dcast(cover.long,site_code+year+block+plot+trt+year_trt ~ Taxon,
                    value.var='max_cover', 
                    fun.aggregate = sum,drop=T,fill=0)
```


```{r}
# Adding in additional info

siteinfo <- biomass_data[site_code %in% sites.long, 
                         .(`site_code`,`site_name`,`continent`,`region`,
                           `first_nutrient_year`,`site_richness`)] %>% 
  distinct()

spsinfo <- select(data.frame(cover.long),site_code,Family:ps_path,-live) %>% distinct()

```

```{r}
cols <- c(colnames(cover.wide)[-c(1:6)])
cover.wide[ , (cols) := lapply(.SD, "as.numeric"), .SDcols = cols]
attr.mat = cover.wide[,1:6]
cover.vals = data.frame(cover.wide[,-c(1:6)])

# Should we normalize?
# cover.mat = round(vegan::decostand(cover.vals, method = "total"), 3)
cover.mat = cover.vals

attr.mat = dummy_columns(attr.mat, select_columns = "trt", 
                           remove_first_dummy = TRUE) %>%
  replace_na(list(trt_K = 0, trt_N = 0, trt_P = 0)) %>%
  mutate(trt_K_num = as.numeric(trt_K * year_trt),
         trt_P_num = as.numeric(trt_P * year_trt),
         trt_N_num = as.numeric(trt_N * year_trt),
         year_trt = as.numeric(year_trt))

attr.mat$trt_K[attr.mat$year_trt == 0] = 0
attr.mat$trt_P[attr.mat$year_trt == 0] = 0
attr.mat$trt_N[attr.mat$year_trt == 0] = 0

# write.csv(x = bind_cols(attr.mat, cover.mat),
#           file = "../data/compmat_edited.csv")

# For all unique sites selected
panov <- function(x, cover.mat, attr.mat){

  # Subset to a single site
  com.subset <- data.frame(cover.mat)[attr.mat$site_code == x,]
  
  # Remove all zero columns
  com.subset = com.subset[,colSums(com.subset) > 0]
  
  # Pull out relevant plot attributes for each site
  attr.subset <- data.frame(attr.mat) %>% filter(site_code == x)
  
  # Check that these two matrices are the same size
  expect_true(nrow(attr.subset) == nrow(com.subset))
  
  mod_anov <- adonis(com.subset ~ as.factor(year_trt) + trt_K_num + trt_P_num + trt_N_num,
                     data = attr.subset, 
                     se = FALSE, method = "bray", 
                     strata = attr.subset$block,
                     by = "margin",
                     permutations = 9999)
    
  # Saving ouput
  output = list(siteinfo = attr.subset,
                aovtable = mod_anov$aov.tab,
                sitescores = mod_anov$coef.sites,
                specscores = mod_anov$coefficients) 
}

sitenames = as.character(unique(attr.mat$site_code))
output = lapply(X = sitenames, FUN = panov, cover.mat = cover.mat, attr.mat = attr.mat)
```

```{r}
storagelist <- list()

for(i in 1:length(output)){

  anovatab = bind_cols(site = as.character(unique(output[[i]]$siteinfo$site_code)),
            data.frame(matrix(output[[i]]$aovtable$`Pr(>F)`, nrow = 1)))
  
  colnames(anovatab)[2:ncol(anovatab)] =   rownames(output[[i]]$aovtable)
  
  storagelist[[i]] = anovatab

  }

write.csv(x = bind_rows(storagelist),
  "../Data/composition_pvalues.csv")

storagelist <- list()

for(i in 1:length(output)){
  sp_scores = data.frame(output[[i]]$specscores[grep("trt_", rownames(output[[i]]$specscores)),])
  
  tomatch = c(4:10)
  # sp_scores = sp_scores[grepl(paste(tomatch, collapse = "|"), rownames(sp_scores)),]
  
  spectab = bind_cols(site = rep(unique(output[[i]]$siteinfo$site_code), nrow(sp_scores)),
                    trt = rownames(sp_scores),
                    sp_scores)
  
  storagelist[[i]] = spectab %>% mutate(trt = gsub("_num", "", trt))

                    # %>%
                    # mutate(trt = gsub("_num).+", "", trt)) %>%
                    # mutate(trt = gsub("as.factor\\(", "", trt)) %>%
                    # group_by(site, trt) %>%
                    # summarise_all(mean)
}

specscores_full = data.frame(bind_rows(storagelist))
specscores_full[is.na(specscores_full)] = 0
write.csv(specscores_full, "../Data/specscores.csv")
```

### Calculate dot-product of pairwise correlations

Given these estimated parameters, we can calculate the correlation between species responses
to different pairs of nutrient treatments through the dot-product of the fitted
vectors between treatments within a site.

After calculating this dot-product, the distributions of each set correlation scores can be seen in histograms below:

* Values close to zero indicate that species responses to two treatments within a site are not correlated with one another.

* Values close to one or negative one indicate that species responses to two treatments within a site are highly positively or negatively correlated.

```{r}
# Normalization function -- squared sums of vector = 1
scalar1 <- function(x) {x / sqrt(sum(x^2))}

# Defining dot-product function
dotprod <- function(x, normalize = TRUE){
  
  # First, select the appropriate treatment and remove columns that aren't plant response
  N_vec <- x %>% filter(trt == "trt_N") %>% select(-trt, -site)
  P_vec <- x %>% filter(trt == "trt_P") %>% select(-trt, -site)
  K_vec <- x %>% filter(trt == "trt_K") %>% select(-trt, -site)
  
  N_change <- sqrt(sum(N_vec^2))
  P_change <- sqrt(sum(P_vec^2))
  K_change <- sqrt(sum(K_vec^2))
  
  # If normalizing, run the normalize function on each vector
  if(normalize == TRUE){
    N_vec <- scalar1(N_vec)
    P_vec <- scalar1(P_vec)
    K_vec <- scalar1(K_vec)
  }
  
  # Generate output dataframe of dot products (pracma::dot function)
  output = data.frame(NP = pracma::dot(as.numeric(N_vec), as.numeric(P_vec)),
                      NK = pracma::dot(as.numeric(N_vec), as.numeric(K_vec)),
                      PK = pracma::dot(as.numeric(P_vec), as.numeric(K_vec)),
                      N_change = N_change,
                      P_change = P_change,
                      K_change = K_change)
  
  return(output)
  
}

# Run over our dataset
dotoutput = specscores_full %>% group_by(site) %>%
  do(dotprod(.))

# Load permANOVA p-value output
site_pvals = read.csv("../Data/composition_pvalues.csv", header = TRUE, stringsAsFactors = FALSE)

# Join all together (sites, treatments, dot-product pairs, perMANOVA p-values)
dot_full = left_join(site_pvals %>% select(-Total, -Residuals), dotoutput) %>% 
  select(-X) %>% 
  rename("trt_K" = "trt_K_num", "trt_P" =  "trt_P_num", "trt_N" = "trt_N_num")

# Write final data product
write.csv(x = dot_full, "../Data/dot_full.csv")
```

In these histograms, I've only showed sites where both nutrient additions in each pair had significant effects in the permutational ANOVA.

I think this output highlights two key patterns:

- Species responses to N & P fertilization and N & K fertilization are not particularly correlated

- Species responses to P & K fertilization tend to be correlated with one another.

```{r, fig.height = 4, fig.width = 10}
p1 = dot_full %>% # filter(trt_N < .05 & trt_P < .05) %>%
  ggplot(aes(x = NP)) +
  geom_histogram(fill = "white", color = "black") +
  xlim(-1, 1) +
  ggtitle("NP Correlation")

p2 = dot_full %>% # filter(trt_N < .05 & trt_K < .05) %>%
  ggplot(aes(x = NK)) +
  geom_histogram(fill = "white", color = "black") +
  xlim(-1, 1) +
  ggtitle("NK Correlation")

p3 = dot_full %>% # filter(trt_K < .05 & trt_P < .05) %>%
  ggplot(aes(x = PK)) +
  geom_histogram(fill = "white", color = "black") +
  xlim(-1, 1) +
  ggtitle("PK Correlation")

grid.arrange(p1,p2,p3,
             top = textGrob("Site Response Correlations",gp=gpar(fontsize=20,font=3)),
             nrow = 1)
```

To get a sense of what sites seem to be showing the strongest or weakest
tradeoffs, I've ranked these scores and plotted them with site labels. Each bar
is filled when the results of the permutational ANOVA indicate that both elements
of the fertilization tradeoff were significant. I don't see evidence here that only significant effects are correlated / uncorrelated.

```{r, fig.height = 15, fig.width = 15}
p1 = dot_full %>% arrange(NP) %>% 
  ggplot(aes(x = c(1:nrow(dot_full)),y = NP,
             fill = trt_P < 0.05 & trt_N < 0.05)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = site), angle = 90) +
  ggtitle("NP Correlation")+
  guides(fill = FALSE) +
  xlab("Site")+
  ylim(-1, 1.2)

p2 = dot_full %>% arrange(NK) %>%
  ggplot(aes(x = c(1:nrow(dot_full)),y = NK,
             fill = trt_K < 0.05 & trt_N < 0.05)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = site), angle = 90) +
  ggtitle("NK Correlation")+
  guides(fill = FALSE) +
  xlab("Site") +
  ylim(-1, 1.2)

p3 = dot_full %>% arrange(PK) %>%
  ggplot(aes(x = c(1:nrow(dot_full)),y = PK,
             fill = trt_P < 0.05 & trt_K < 0.05)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = site), angle = 90) +
  ggtitle("PK Correlation") +
  guides(fill = FALSE) +
  xlab("Site")+
  ylim(-1, 1.2)

grid.arrange(p1,p2,p3,
             top = textGrob("Site Response Correlations Filled By Significance",gp=gpar(fontsize=20,font=3)),
             nrow = 2)
```

# Proof of concept

I've also highlighted a couple of these below, plotting a db-RDA of the same
model used to generate the species responses to the different nutrients. This is
mostly a proof of concept. Are the values we extract from this metric pretty similar
to our results if we just examine the angles between vectors in an ordination? Answer seems to be yes, though this
is not a direct representation of the model used above.

```{r, fig.width= 12, fig.height= 5}
capFit = function(site){
  com.subset <- data.frame(cover.mat)[attr.mat$site_code == site,]
  
  # Remove all zero columns
  com.subset = com.subset[,colSums(com.subset) > 0]
  
  # Pull out relevant plot attributes for each site
  attr.subset <- data.frame(attr.mat) %>% filter(site_code == site)
  
  # Check that these two matrices are the same size
  expect_true(nrow(attr.subset) == nrow(com.subset))
  
  # Generate and return an NMDS figure
  mod_out = vegan::capscale(com.subset ~ as.factor(year_trt) + trt_K + trt_P + trt_N,
                     data = attr.subset)
  
  return(mod_out)
  
}

par(mfrow = c(1, 3))

plot(capFit("pinj.au"), main = "Pinjarra - Stronger Negative N-P Correlation, value = -0.4")
plot(capFit("hopl.us"), main = "Hopland - No N-P Correlation, value = 0.1")
plot(capFit("konz.us"), main = "Konza - Strong Positive N-P Correlation, value = 0.9")
```

